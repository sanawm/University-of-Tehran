{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from game import Game\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_map_files(directory):\n",
    "    pattern = re.compile(r'^map(\\d+)\\.txt$')\n",
    "    map_file_indices = []\n",
    "\n",
    "    for file_name in os.listdir(directory):\n",
    "        match = pattern.match(file_name)\n",
    "        if match:\n",
    "            map_file_indices.append(match.group(1))\n",
    "\n",
    "    return [int(idx) for idx in map_file_indices]\n",
    "\n",
    "def is_valid_input(map, indices, algorithm, solvers):\n",
    "    valid_input = True\n",
    "    if map not in indices:\n",
    "        print(f\"Map index out of range. Please choose within range {min(indices)} to {max(indices)}\")\n",
    "        valid_input = False\n",
    "    if algorithm not in solvers.keys():    \n",
    "        print(f\"{algorithm} is not a defined algorithm. Please choose from\", *[f\"{solver} ({i+1})  \" for i, solver in enumerate(solvers.keys())])\n",
    "        valid_input = False\n",
    "    return valid_input\n",
    "\n",
    "def load_map(map_index):  \n",
    "    file_name = \"map\" + str(map_index) + \".txt\"\n",
    "    with open('./assets/maps/' + file_name) as f:\n",
    "        game_map = f.read()\n",
    "    return game_map\n",
    "\n",
    "map_file_indices = extract_map_files(\"./assets/maps/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BFS code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import time\n",
    "\n",
    "def solver_bfs(game_map):\n",
    "    game = Game(game_map)\n",
    "    initial_state = (game.get_player_position(), tuple(game.get_box_locations()))\n",
    "    queue = deque([(initial_state, \"\")])\n",
    "    visited = set()\n",
    "    visited.add(initial_state)\n",
    "    directions = {'U': (-1, 0), 'D': (1, 0), 'L': (0, -1), 'R': (0, 1)}\n",
    "    \n",
    "    states_explored = 0\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    while queue:\n",
    "        (player_pos, box_positions), moves = queue.popleft()\n",
    "        states_explored += 1\n",
    "        \n",
    "        game.set_player_position(player_pos)\n",
    "        game.set_box_positions(box_positions)\n",
    "        \n",
    "        if game.is_game_won():\n",
    "            return moves, states_explored, time.perf_counter() - start_time\n",
    "        \n",
    "        for move, (dy, dx) in directions.items():\n",
    "            new_player_pos = game._Game__calculate_new_pos(player_pos, (dy, dx))  # Use portal-aware movement\n",
    "            \n",
    "            if game.is_wall(new_player_pos):  # Check if player can move\n",
    "                continue\n",
    "            \n",
    "            new_box_positions = list(box_positions)\n",
    "            if new_player_pos in box_positions:\n",
    "                box_index = box_positions.index(new_player_pos)\n",
    "                new_box_pos = game._Game__calculate_new_pos(new_player_pos, (dy, dx))  # Portal-aware box movement\n",
    "                \n",
    "                if not game.is_wall(new_box_pos) and new_box_pos not in box_positions:\n",
    "                    new_box_positions[box_index] = new_box_pos\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            new_state = (new_player_pos, tuple(new_box_positions))\n",
    "            if new_state not in visited:\n",
    "                visited.add(new_state)\n",
    "                queue.append((new_state, moves + move))\n",
    "    \n",
    "    return None, states_explored, time.perf_counter() - start_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description:\n",
    "First, it initializes the game using the Game class and determines the initial position of the player and boxes. Then, it places this state, along with an empty move string, into a queue and adds it to a visited set to avoid revisiting states.\n",
    "The algorithm explores states by dequeuing the oldest state from the queue. It sets the player and box positions in the game and checks if the game is won. If so, it returns the sequence of moves, the number of explored states, and the elapsed time.\n",
    "For each possible movement direction (up, down, left, right), it calculates the new player position, considering portal mechanics. If the new position is a wall, it skips the move. If the player moves onto a box, it calculates the box’s new position. If the box's new position is valid (not a wall or another box), it updates the box's position.\n",
    "If the new state (player position and box positions) is not visited, it adds it to the visited set and appends it to the queue with the updated move sequence.\n",
    "If the queue becomes empty without finding a solution, it returns None and the number of explored states, indicating no BFS solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BFS test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = load_map(1)\n",
    "game = Game(game_map)\n",
    "game.display_map()\n",
    "\n",
    "solution, visited_states, execution_time = solver_bfs(game_map)\n",
    "if solution:\n",
    "    print(\"BFS Solution found:\", solution)\n",
    "    game.apply_moves(solution)\n",
    "    #game.display_map()\n",
    "else:\n",
    "    print(\"No BFS solution found.\")\n",
    "\n",
    "print(\"BFS Visited states:\", visited_states)\n",
    "print(f\"BFS Execution time: {execution_time:.6f} seconds\")\n",
    "\n",
    "#Verification\n",
    "#if game.is_game_won():\n",
    "#    print(\"Game is won!\")\n",
    "#else:\n",
    "#    print(\"Game is not won yet.\")\n",
    "\n",
    "#game.display_map()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DFS code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import time\n",
    "\n",
    "def solver_dfs(game_map):\n",
    "    game = Game(game_map)\n",
    "    initial_state = (game.get_player_position(), tuple(game.get_box_locations()))\n",
    "    stack = [(initial_state, \"\", 0)]  # (state, moves, depth)\n",
    "    visited = {}\n",
    "    directions = {'U': (-1, 0), 'D': (1, 0), 'L': (0, -1), 'R': (0, 1)}\n",
    "    \n",
    "    states_explored = 0\n",
    "    start_time = time.perf_counter()\n",
    "    best_solution = None\n",
    "    best_solution_length = float('inf')\n",
    "    \n",
    "    while stack:\n",
    "        (player_pos, box_positions), moves, depth = stack.pop()\n",
    "        states_explored += 1\n",
    "        \n",
    "        game.set_player_position(player_pos)\n",
    "        game.set_box_positions(box_positions)\n",
    "        \n",
    "        if game.is_game_won():\n",
    "            if len(moves) < best_solution_length:\n",
    "                best_solution = moves\n",
    "                best_solution_length = len(moves)\n",
    "            continue\n",
    "        \n",
    "        if depth >= best_solution_length:\n",
    "            continue \n",
    "        \n",
    "        for move, (dy, dx) in directions.items():\n",
    "            new_player_pos = game._Game__calculate_new_pos(player_pos, (dy, dx))\n",
    "            \n",
    "            if game.is_wall(new_player_pos): \n",
    "                continue\n",
    "            \n",
    "            new_box_positions = list(box_positions)\n",
    "            if new_player_pos in box_positions:\n",
    "                box_index = box_positions.index(new_player_pos)\n",
    "                new_box_pos = game._Game__calculate_new_pos(new_player_pos, (dy, dx))  \n",
    "                \n",
    "                if not game.is_wall(new_box_pos) and new_box_pos not in box_positions:\n",
    "                    new_box_positions[box_index] = new_box_pos\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            new_state = (new_player_pos, tuple(new_box_positions))\n",
    "            if new_state not in visited or len(moves) + 1 < visited[new_state]:\n",
    "                visited[new_state] = len(moves) + 1\n",
    "                stack.append((new_state, moves + move, depth + 1))\n",
    "    \n",
    "    return (best_solution if best_solution else None), states_explored, time.perf_counter() - start_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description: DFS explores possible moves by always diving deeper into a path before backtracking. This implementation uses a stack to track states, prioritizing last-in-first-out traversal. The algorithm starts with the initial player and box positions and iterates through possible movements. It checks if the goal state is reached, updating the best solution if a shorter path is found. To optimize, it prunes deeper searches if they exceed the best-known solution length. Movements are portal-aware, ensuring valid transitions. If a new state offers a shorter path than previously recorded, it is explored further. The function returns the shortest move sequence, the number of explored states, and the execution time. If no solution exists, it returns None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DFS test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = load_map(1)\n",
    "game = Game(game_map)\n",
    "game.display_map()\n",
    "\n",
    "solution, visited_states, execution_time = solver_dfs(game_map)\n",
    "if solution:\n",
    "    print(\"DFS Solution found:\", solution)\n",
    "    game.apply_moves(solution)\n",
    "    #game.display_map()\n",
    "else:\n",
    "    print(\"No DFS solution found.\")\n",
    "\n",
    "print(\"DFS Visited states:\", visited_states)\n",
    "print(f\"DFS Execution time: {execution_time:.6f} seconds\")\n",
    "\n",
    "#Verification\n",
    "#if game.is_game_won():\n",
    "#    print(\"Game is won!\")\n",
    "#else:\n",
    "#    print(\"Game is not won yet.\")\n",
    "\n",
    "#game.display_map()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDS code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import deque\n",
    "\n",
    "def dfs_with_depth_limit(game, depth_limit):\n",
    "    queue = deque([(game.get_player_position(), tuple(game.get_box_locations()), \"\", 0)])  \n",
    "    visited_states = set()\n",
    "\n",
    "    while queue:\n",
    "        player_pos, box_positions, path, depth = queue.popleft()\n",
    "\n",
    "        if all(box == goal for box, goal in zip(box_positions, game.get_goal_locations())):\n",
    "            return path, len(visited_states)\n",
    "\n",
    "        if depth >= depth_limit:\n",
    "            continue \n",
    "\n",
    "        state = (player_pos, box_positions)\n",
    "        if state in visited_states:\n",
    "            continue\n",
    "        visited_states.add(state)\n",
    "\n",
    "        for direction in ['U', 'L', 'D', 'R']:\n",
    "            new_game = Game(game.get_map())\n",
    "            new_game.set_player_position(player_pos)\n",
    "            new_game.set_box_positions(box_positions)\n",
    "\n",
    "            if new_game.apply_move(direction):\n",
    "                new_state = (new_game.get_player_position(), tuple(new_game.get_box_locations()))\n",
    "                if new_state not in visited_states:\n",
    "                    queue.append((new_game.get_player_position(), tuple(new_game.get_box_locations()), path + direction, depth + 1))\n",
    "\n",
    "    return None, len(visited_states)\n",
    "\n",
    "def solver_ids(game_map):\n",
    "    game = Game(game_map)\n",
    "    depth_limit = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        result, visited_states_count = dfs_with_depth_limit(game, depth_limit)\n",
    "\n",
    "        if result:\n",
    "            execution_time = time.time() - start_time\n",
    "            return result, visited_states_count, execution_time  \n",
    "\n",
    "        depth_limit += 1 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description: The solver_ids function starts with a depth of 0 and repeatedly calls dfs_with_depth_limit, increasing the depth limit until a solution is found. In dfs_with_depth_limit, a depth-first search (DFS) explores possible moves (U, L, D, R), tracking visited states to prevent redundant computations.\n",
    "Each move updates the game state, and if all boxes are on their goals, the function returns the move sequence. IDS ensures optimality by always finding the shortest path first while using less memory than Breadth-First Search (BFS). The output includes the shortest move sequence, the number of visited states, and the execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDS test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_map = load_map(1)\n",
    "game = Game(game_map)\n",
    "game.display_map()\n",
    "\n",
    "solution, visited_states, execution_time = solver_ids(game_map)\n",
    "if solution:\n",
    "    print(\"IDS Solution found:\", solution)\n",
    "    game.apply_moves(solution)\n",
    "    # game.display_map()\n",
    "else:\n",
    "    print(\"No IDS solution found.\")\n",
    "\n",
    "print(\"IDS Visited states:\", visited_states)\n",
    "print(f\"IDS Execution time: {execution_time:.6f} seconds\")\n",
    "\n",
    "#Verification\n",
    "#if game.is_game_won():\n",
    "#    print(\"Game is won!\")\n",
    "#else:\n",
    "#    print(\"Game is not won yet.\")\n",
    "\n",
    "#game.display_map()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A* code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def manhattan_distance(pos1, pos2):\n",
    "    return abs(pos1[0] - pos2[0]) + abs(pos1[1] - pos2[1])\n",
    "def basic_heuristic(game):\n",
    "    total_distance = sum(\n",
    "        manhattan_distance(box, goal) for box, goal in zip(game.get_box_locations(), game.get_goal_locations())\n",
    "    )\n",
    "    player_to_box = min(\n",
    "        (manhattan_distance(game.get_player_position(), box) for box in game.get_box_locations()),\n",
    "        default=0\n",
    "    )\n",
    "    return total_distance + player_to_box\n",
    "def improved_heuristic(game, weight=1):\n",
    "    total_distance = 0\n",
    "    for box, goal in zip(game.get_box_locations(), game.get_goal_locations()):\n",
    "        total_distance += manhattan_distance(box, goal)\n",
    "\n",
    "    player_to_nearest_box = min(\n",
    "        (manhattan_distance(game.get_player_position(), box) for box in game.get_box_locations()),\n",
    "        default=0\n",
    "    )\n",
    "    return total_distance + weight * player_to_nearest_box\n",
    "\n",
    "def solver_astar(game_map, heuristic_func=improved_heuristic, weight=1):\n",
    "    game = Game(game_map)\n",
    "    priority_queue = []\n",
    "    visited = set()\n",
    "    initial_state = (game.get_player_position(), tuple(game.get_box_locations()))\n",
    "    heapq.heappush(priority_queue, (0, \"\", initial_state))\n",
    "    visited.add(initial_state)\n",
    "    \n",
    "    while priority_queue:\n",
    "        cost, moves, (player_pos, box_positions) = heapq.heappop(priority_queue)\n",
    "        \n",
    "        game.set_player_position(player_pos)\n",
    "        game.set_box_positions(box_positions)\n",
    "        \n",
    "        if game.is_game_won():\n",
    "            return moves, len(visited)\n",
    "        \n",
    "        for move in \"UDLR\":\n",
    "            new_game = Game(game_map)\n",
    "            new_game.set_player_position(player_pos)\n",
    "            new_game.set_box_positions(box_positions)\n",
    "            \n",
    "            if new_game.apply_move(move):\n",
    "                new_state = (new_game.get_player_position(), tuple(new_game.get_box_locations()))\n",
    "                if new_state not in visited:\n",
    "                    visited.add(new_state) \n",
    "                    heuristic_value = heuristic_func(new_game, weight)\n",
    "                    \n",
    "                    new_cost = len(moves) + 1 + heuristic_value\n",
    "                    heapq.heappush(priority_queue, (new_cost, moves + move, new_state))\n",
    "    \n",
    "    return \"no solution\", len(visited)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description:\n",
    "The Manhattan distance heuristic is a common choice for problems involving movement on a grid. In this problem, a simple heuristic could be:\n",
    "\n",
    "$$\n",
    "h = \\sum_{i=1}^{n} \\left( \\text{Manhattan distance from player to box}_i + \\text{Manhattan distance from box}_i \\text{ to goal}_i \\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "The Manhattan distance is calculated as:\n",
    "$$\n",
    "|x_1 - x_2| + |y_1 - y_2|\n",
    "$$\n",
    "\n",
    "\\( n \\) is the number of boxes.\n",
    "\n",
    "### Problems with the Basic Manhattan Distance Heuristic\n",
    "- **Ignoring Obstacles**: This heuristic does not consider walls or other obstacles that might make the shortest path longer.\n",
    "- **Ignoring Box Interactions**: If boxes block each other, the heuristic does not account for the extra moves needed to rearrange them.\n",
    "- **Deadlocks**: The heuristic does not consider whether a box has been pushed into a position where it can no longer reach the goal.\n",
    "\n",
    "### Improved Heuristic\n",
    "A better heuristic should account for:\n",
    "- Walls and obstacles.\n",
    "- Box dependencies (i.e., preventing movements that lead to unsolvable positions).\n",
    "- Identifying deadlocks early.\n",
    "\n",
    "An improved version could be:\n",
    "\n",
    "$$\n",
    "h = \\sum_{i=1}^{n} d(\\text{box}_i, \\text{goal}_i) + w \\cdot d(\\text{player}, \\text{nearest box})\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- d(box i , goal i) is the Manhattan distance from each box to its goal.\n",
    "- d(player, nearest box) is the Manhattan distance from the player to the nearest box.\n",
    "- w is a weight to prioritize moving the player efficiently.\n",
    "\n",
    "**Why is the weight factor \\( w \\) necessary?**\n",
    "\n",
    "If the value of this weight is very small (w approx 0), it means the heuristic focuses only on the movement of the boxes and ignores the player's position. In this case, A* may explore incorrect paths because it assumes the player can easily reach any box.\n",
    "\n",
    "If the value of this weight is very large, it means the heuristic places too much importance on the player's position. This could cause the algorithm to focus more on the player's movement rather than solving the problem, which is not always helpful.\n",
    "\n",
    "**How do we choose the appropriate value for \\( w \\)?**\n",
    "\n",
    "✅ We select a balanced value, for example:\n",
    "\n",
    "- \\( w = 1 \\) if the movement of the player and the movement of the boxes are of roughly equal importance.\n",
    "- \\( w > 1 \\) if the player's movement is much more difficult, and we need to find better paths to get the player to the boxes.\n",
    "- \\( w < 1 \\) if the primary focus is on the boxes and the player's movement is easy.\n",
    "\n",
    "Additionally:\n",
    "- Penalize states where a box is in a deadlock position (e.g., against a wall and not in a goal position).\n",
    "- Use a modified distance metric (e.g., consider obstacles in a BFS-based distance calculation).\n",
    "\n",
    "Now, let's implement the A* solver with the improved heuristic.\n",
    "\n",
    "### A* Solver\n",
    "Explanation of the A* Algorithm:\n",
    "- **Priority Queue**: A min-heap is used to explore the most promising states first.\n",
    "- **State Representation**: The state is defined by the player's position and the positions of all boxes.\n",
    "- **Heuristic Calculation**: Uses the improved heuristic to estimate the cost to the goal.\n",
    "- **Exploration**: Each possible move is attempted, and valid moves are pushed into the priority queue.\n",
    "- **Termination**: The algorithm returns the optimal sequence of moves when the goal state is reached or reports \"no solution\" if no solution exists.\n",
    "\n",
    "This improved heuristic considers both player and box positions while also accounting for movement complexity, making A* find an optimal solution efficiently. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A* Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "game_map = load_map(2)\n",
    "game = Game(game_map)\n",
    "game.display_map()\n",
    "\n",
    "solution, visited_states = solver_astar(game_map)\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "if solution != \"no solution\":\n",
    "    print(\"A* Solution found:\", solution)\n",
    "    game.apply_moves(solution)\n",
    "else:\n",
    "    print(\"No A* solution found.\")\n",
    "\n",
    "print(\"A* Visited states:\", visited_states)\n",
    "print(f\"A* Execution time: {execution_time:.6f} seconds\")\n",
    "\n",
    "#Verification\n",
    "#if game.is_game_won():\n",
    "#    print(\"Game is won!\")\n",
    "#else:\n",
    "#    print(\"Game is not won yet.\")\n",
    "\n",
    "#game.display_map()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted A* code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def manhattan_distance(pos1, pos2):\n",
    "    return abs(pos1[0] - pos2[0]) + abs(pos1[1] - pos2[1])\n",
    "def improved_heuristic(game, weight=1):\n",
    "    total_distance = 0\n",
    "    for box, goal in zip(game.get_box_locations(), game.get_goal_locations()):\n",
    "        total_distance += manhattan_distance(box, goal)\n",
    "\n",
    "    player_to_nearest_box = min(\n",
    "        (manhattan_distance(game.get_player_position(), box) for box in game.get_box_locations()),\n",
    "        default=0\n",
    "    )\n",
    "    return total_distance + weight * player_to_nearest_box\n",
    "\n",
    "\n",
    "def solver_weighted_astar(game_map, heuristic_func=improved_heuristic, weight=1):\n",
    "    game = Game(game_map)\n",
    "    priority_queue = []\n",
    "    visited = set()\n",
    "    initial_state = (game.get_player_position(), tuple(game.get_box_locations()))\n",
    "    heapq.heappush(priority_queue, (0, \"\", initial_state))\n",
    "    visited.add(initial_state)\n",
    "    \n",
    "    while priority_queue:\n",
    "        cost, moves, (player_pos, box_positions) = heapq.heappop(priority_queue)\n",
    "        \n",
    "        game.set_player_position(player_pos)\n",
    "        game.set_box_positions(box_positions)\n",
    "        \n",
    "        if game.is_game_won():\n",
    "            return moves, len(visited)\n",
    "        \n",
    "        for move in \"UDLR\":\n",
    "            new_game = Game(game_map)\n",
    "            new_game.set_player_position(player_pos)\n",
    "            new_game.set_box_positions(box_positions)\n",
    "            \n",
    "            if new_game.apply_move(move):\n",
    "                new_state = (new_game.get_player_position(), tuple(new_game.get_box_locations()))\n",
    "                if new_state not in visited:\n",
    "                    visited.add(new_state) \n",
    "                    heuristic_value = heuristic_func(new_game, weight)\n",
    "                    new_cost = len(moves) + 1 + weight * heuristic_value\n",
    "                    heapq.heappush(priority_queue, (new_cost, moves + move, new_state))\n",
    "    \n",
    "    return \"no solution\", len(visited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description:**\n",
    "Weighted A* is a variant of the A* algorithm that prioritizes heuristic information more aggressively by multiplying the heuristic function by a weight factor 𝑤. This often speeds up the search but can lead to suboptimal solutions if w is too large.\n",
    "The cost function in Weighted A* is defined as:\n",
    "$$\n",
    "f(n)=g(n)+w×h(n)\n",
    "$$\n",
    "\n",
    "f(n) = Total estimated cost from the start to the goal through node \n",
    "g(n) = Cost from the start node to \n",
    "h(n) = Heuristic estimate of the cost from \n",
    "w = Weight factor that amplifies the heuristic’s influence\n",
    "\n",
    "**Functions and Their Roles in the Code:**\n",
    "\n",
    "1. Heuristic Function: h(n)\n",
    "The heuristic estimates the remaining cost to reach the goal.\n",
    "Basic Manhattan Distance Heuristic: ( Common choices)\n",
    "$$\n",
    "ℎ\n",
    "(\n",
    "𝑛\n",
    ")\n",
    "=\n",
    "∑\n",
    "𝑖\n",
    "Manhattan distance between box \n",
    "𝑖\n",
    " and its goal\n",
    "$$\n",
    "Improved Heuristic:\n",
    "Adds distance from the player to the nearest box to prioritize reachable boxes.\n",
    "Penalizes boxes that are stuck in corners or unreachable states.\n",
    "Uses weighted multipliers to balance between efficiency and accuracy.\n",
    "\n",
    "\n",
    "2. Cost Function: g(n)\n",
    "it is the actual cost from the start node to the current node. In this case, each move costs 1, so:\n",
    "$$\n",
    "g(n)=number of moves taken so far\n",
    "$$\n",
    "This ensures that shorter paths are preferred when expanding nodes.\n",
    "\n",
    "\n",
    "\n",
    "**Tuning Weighted A for Optimal Performance:**\n",
    "1. Reduce the Weight: \n",
    "if w is too high, the search will prioritize the heuristic too much and ignore shorter paths.\n",
    "Solution: w must be 1.1 – 1.5 for better balance\n",
    "\n",
    "2. Improve the Heuristic Function:\n",
    "Identify trapped boxes: If a box is in a corner and cannot reach the goal, assign it a very high heuristic value.\n",
    "Consider box sequences: If a box is blocking another box’s path, add a penalty\n",
    "\n",
    "\n",
    "3. Increase g(n) Consideration:\n",
    "If the algorithm is prioritizing the heuristic too much, it might ignore paths that have a lower real cost.\n",
    "Solution: Make sure g(n) properly affects the cost:\n",
    "f(n) = g(n) + w*h(n)\n",
    "If needed, increase the effect of g(n) by tweaking the weight of w.\n",
    "\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "1. Weighted A* is a faster but sometimes suboptimal version of A*.\n",
    "2. Lowering w helps find the shortest path.\n",
    "3. Better heuristics (considering box traps, player movement) improve accuracy.\n",
    "4. Balancig g(n) and h(n) ensures optimal solutions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted A* test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "game_map = load_map(5) \n",
    "game = Game(game_map)\n",
    "game.display_map()\n",
    "game.is_game_won();\n",
    "solution, visited_states = solver_weighted_astar(game_map,weight=1.5)\n",
    "execution_time = time.time() - start_time\n",
    "\n",
    "if solution != \"no solution\":\n",
    "    print(\"Weighted A* Solution found:\", solution)\n",
    "    game.apply_moves(solution)\n",
    "else:\n",
    "    print(\"No Weighted A* solution found.\")\n",
    "\n",
    "print(\"Weighted A* Visited states:\", visited_states)\n",
    "print(f\"Weighted A* Execution time: {execution_time:.6f} seconds\")\n",
    "\n",
    "#Verification\n",
    "#if game.is_game_won():\n",
    "#    print(\"Game is won!\")\n",
    "#else:\n",
    "#    print(\"Game is not won yet.\")\n",
    "\n",
    "#game.display_map()  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
